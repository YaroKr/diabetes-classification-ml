{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \u2696\ufe0f Notebook 05C: Sampling Strategy Battle\n",
    "\n",
    "**Objective:** Find optimal sampling strategy for top 2 models\n",
    "\n",
    "**From Phase 2:**\n",
    "- \ud83e\udd47 **Winner:** AdaBoost (76.4% recall, 29.0% precision)\n",
    "- \ud83e\udd48 **Runner-up:** CatBoost (75.0% recall, 33.3% precision)\n",
    "\n",
    "**Critical Questions:**\n",
    "1. Can SMOTE push recall from 76% to 80%?\n",
    "2. Can undersampling improve precision without hurting recall?\n",
    "3. Is baseline (class weights only) already optimal?\n",
    "\n",
    "**Test Matrix (6 Combinations):**\n",
    "- **AdaBoost:** Baseline, SMOTE, RandomUnderSampler\n",
    "- **CatBoost:** Baseline, SMOTE, RandomUnderSampler\n",
    "\n",
    "**Selection Criteria:**\n",
    "- **Primary:** Recall \u2265 70% (non-negotiable)\n",
    "- **Secondary:** Maximize Precision (reduce false alarms)\n",
    "- **Balance:** F1-Score for overall performance\n",
    "\n",
    "**Expected Outcome:**\n",
    "- SMOTE may increase recall but decrease precision\n",
    "- Undersampling may balance recall-precision better\n",
    "- Baseline might still be optimal (already 76.4%)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udce6 Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, recall_score, precision_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, balanced_accuracy_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "\n",
    "print(\"\u2705 Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Step 2: Load Data & Phase 2 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"LOADING DATA & PHASE 2 RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('selected_features_05A.csv')\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Dataset: {df.shape[0]:,} rows \u00d7 {df.shape[1]} columns\")\n",
    "print(f\"   Features: {X.shape[1]}\")\n",
    "\n",
    "# Class distribution\n",
    "class_counts = y.value_counts().sort_index()\n",
    "print(f\"\\n\ud83d\udcca Target Distribution:\")\n",
    "print(f\"   Class 0 (Healthy):  {class_counts[0]:,} ({class_counts[0]/len(y)*100:.2f}%)\")\n",
    "print(f\"   Class 1 (At Risk):  {class_counts[1]:,} ({class_counts[1]/len(y)*100:.2f}%)\")\n",
    "print(f\"   Imbalance ratio: {class_counts[0]/class_counts[1]:.1f}:1\")\n",
    "\n",
    "# Load Phase 2 results\n",
    "with open('top_2_models_selection.json', 'r') as f:\n",
    "    phase2_results = json.load(f)\n",
    "\n",
    "print(f\"\\n\ud83d\udccb Phase 2 Winners:\")\n",
    "print(f\"   \ud83e\udd47 {phase2_results['winner']['name']}: {phase2_results['winner']['recall_mean']:.3f} recall\")\n",
    "print(f\"   \ud83e\udd48 {phase2_results['runner_up']['name']}: {phase2_results['runner_up']['recall_mean']:.3f} recall\")\n",
    "\n",
    "# Calculate scale_pos_weight\n",
    "scale_pos_weight = class_counts[0] / class_counts[1]\n",
    "print(f\"\\n\ud83d\udca1 scale_pos_weight for boosting: {scale_pos_weight:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd00 Step 3: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Split:\")\n",
    "print(f\"   Train: {X_train.shape[0]:,} samples\")\n",
    "print(f\"   Test:  {X_test.shape[0]:,} samples\")\n",
    "\n",
    "# Verify stratification\n",
    "train_dist = y_train.value_counts(normalize=True).sort_index()\n",
    "test_dist = y_test.value_counts(normalize=True).sort_index()\n",
    "\n",
    "print(f\"\\n\u2705 Stratification verified:\")\n",
    "print(f\"   Train At-Risk: {train_dist[1]:.3f}\")\n",
    "print(f\"   Test At-Risk:  {test_dist[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Step 4: Define 3 Sampling Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DEFINING 3 SAMPLING STRATEGIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n\ud83d\udccb Strategies to Test:\")\n",
    "print(\"\\n1\ufe0f\u20e3 BASELINE: Class Weights Only\")\n",
    "print(\"   \u2022 No resampling\")\n",
    "print(\"   \u2022 Uses scale_pos_weight or class_weight='balanced'\")\n",
    "print(\"   \u2022 Baseline from Phase 2 (AdaBoost: 76.4%, CatBoost: 75.0%)\")\n",
    "\n",
    "print(\"\\n2\ufe0f\u20e3 SMOTE: Synthetic Minority Over-sampling\")\n",
    "print(\"   \u2022 Creates synthetic At-Risk samples\")\n",
    "print(\"   \u2022 Balances training data to 1:1 ratio\")\n",
    "print(\"   \u2022 May increase recall but decrease precision\")\n",
    "print(f\"   \u2022 Will create ~{class_counts[0] - class_counts[1]:,} synthetic At-Risk samples\")\n",
    "\n",
    "print(\"\\n3\ufe0f\u20e3 RandomUnderSampler: Majority Under-sampling\")\n",
    "print(\"   \u2022 Randomly removes Healthy samples\")\n",
    "print(\"   \u2022 Balances training data to 1:1 ratio\")\n",
    "print(\"   \u2022 May improve precision, risk losing recall\")\n",
    "print(f\"   \u2022 Will remove ~{class_counts[0] - class_counts[1]:,} Healthy samples\")\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Why Test All 3?\")\n",
    "print(\"   \u2022 SMOTE: May push recall 76% \u2192 80%\")\n",
    "print(\"   \u2022 Undersampling: May improve precision 29% \u2192 35%\")\n",
    "print(\"   \u2022 Baseline: Might already be optimal (no overfitting)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\udd16 Step 5: Define Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DEFINING MODEL CONFIGURATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define base estimator for AdaBoost (CRITICAL!)\n",
    "ada_base = DecisionTreeClassifier(\n",
    "    max_depth=3,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n\ud83e\udd47 AdaBoost Configuration:\")\n",
    "print(\"   \u2022 Base Estimator: DecisionTreeClassifier(max_depth=3, class_weight='balanced')\")\n",
    "print(\"   \u2022 n_estimators: 100\")\n",
    "print(\"   \u2022 algorithm: SAMME\")\n",
    "print(\"   \u2022 This config achieved 76.4% recall in Phase 2\")\n",
    "\n",
    "print(\"\\n\ud83e\udd48 CatBoost Configuration:\")\n",
    "print(f\"   \u2022 scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "print(\"   \u2022 iterations: 100\")\n",
    "print(\"   \u2022 This config achieved 75.0% recall in Phase 2\")\n",
    "\n",
    "print(\"\\n\u26a0\ufe0f CRITICAL: These exact configs must be used!\")\n",
    "print(\"   Otherwise results won't match Phase 2 baseline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\uddea Step 6: Test AdaBoost with 3 Sampling Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TESTING ADABOOST WITH 3 SAMPLING STRATEGIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ada_results = []\n",
    "\n",
    "# Strategy 1: Baseline (Class Weights Only)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"1\ufe0f\u20e3 AdaBoost + BASELINE (Class Weights Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "ada_baseline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=3, class_weight='balanced', random_state=42),\n",
    "        n_estimators=100,\n",
    "        algorithm='SAMME',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "start = time.time()\n",
    "ada_baseline.fit(X_train, y_train)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "y_pred = ada_baseline.predict(X_test)\n",
    "y_pred_proba = ada_baseline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Results:\")\n",
    "print(f\"   Recall:    {recall:.3f} \u2190 PRIMARY\")\n",
    "print(f\"   Precision: {precision:.3f}\")\n",
    "print(f\"   F1-Score:  {f1:.3f}\")\n",
    "print(f\"   ROC-AUC:   {roc_auc:.3f}\")\n",
    "print(f\"   Time:      {elapsed:.1f}s\")\n",
    "print(f\"\\n   TP: {tp:,} | FP: {fp:,} | FN: {fn:,} | TN: {tn:,}\")\n",
    "\n",
    "ada_results.append({\n",
    "    'Model': 'AdaBoost',\n",
    "    'Strategy': 'Baseline',\n",
    "    'Recall': recall,\n",
    "    'Precision': precision,\n",
    "    'F1': f1,\n",
    "    'ROC_AUC': roc_auc,\n",
    "    'Time': elapsed,\n",
    "    'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn\n",
    "})\n",
    "\n",
    "# Strategy 2: SMOTE\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2\ufe0f\u20e3 AdaBoost + SMOTE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "ada_smote = ImbPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=3, class_weight='balanced', random_state=42),\n",
    "        n_estimators=100,\n",
    "        algorithm='SAMME',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "start = time.time()\n",
    "ada_smote.fit(X_train, y_train)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "y_pred = ada_smote.predict(X_test)\n",
    "y_pred_proba = ada_smote.predict_proba(X_test)[:, 1]\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Results:\")\n",
    "print(f\"   Recall:    {recall:.3f} \u2190 PRIMARY\")\n",
    "print(f\"   Precision: {precision:.3f}\")\n",
    "print(f\"   F1-Score:  {f1:.3f}\")\n",
    "print(f\"   ROC-AUC:   {roc_auc:.3f}\")\n",
    "print(f\"   Time:      {elapsed:.1f}s\")\n",
    "print(f\"\\n   TP: {tp:,} | FP: {fp:,} | FN: {fn:,} | TN: {tn:,}\")\n",
    "\n",
    "ada_results.append({\n",
    "    'Model': 'AdaBoost',\n",
    "    'Strategy': 'SMOTE',\n",
    "    'Recall': recall,\n",
    "    'Precision': precision,\n",
    "    'F1': f1,\n",
    "    'ROC_AUC': roc_auc,\n",
    "    'Time': elapsed,\n",
    "    'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn\n",
    "})\n",
    "\n",
    "# Strategy 3: RandomUnderSampler\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3\ufe0f\u20e3 AdaBoost + RandomUnderSampler\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "ada_under = ImbPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('undersample', RandomUnderSampler(random_state=42)),\n",
    "    ('classifier', AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=3, class_weight='balanced', random_state=42),\n",
    "        n_estimators=100,\n",
    "        algorithm='SAMME',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "start = time.time()\n",
    "ada_under.fit(X_train, y_train)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "y_pred = ada_under.predict(X_test)\n",
    "y_pred_proba = ada_under.predict_proba(X_test)[:, 1]\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Results:\")\n",
    "print(f\"   Recall:    {recall:.3f} \u2190 PRIMARY\")\n",
    "print(f\"   Precision: {precision:.3f}\")\n",
    "print(f\"   F1-Score:  {f1:.3f}\")\n",
    "print(f\"   ROC-AUC:   {roc_auc:.3f}\")\n",
    "print(f\"   Time:      {elapsed:.1f}s\")\n",
    "print(f\"\\n   TP: {tp:,} | FP: {fp:,} | FN: {fn:,} | TN: {tn:,}\")\n",
    "\n",
    "ada_results.append({\n",
    "    'Model': 'AdaBoost',\n",
    "    'Strategy': 'UnderSample',\n",
    "    'Recall': recall,\n",
    "    'Precision': precision,\n",
    "    'F1': f1,\n",
    "    'ROC_AUC': roc_auc,\n",
    "    'Time': elapsed,\n",
    "    'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn\n",
    "})\n",
    "\n",
    "print(\"\\n\u2705 AdaBoost testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\uddea Step 7: Test CatBoost with 3 Sampling Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING CATBOOST WITH 3 SAMPLING STRATEGIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cat_results = []\n",
    "\n",
    "# Strategy 1: Baseline\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"4\ufe0f\u20e3 CatBoost + BASELINE (scale_pos_weight)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cat_baseline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', CatBoostClassifier(\n",
    "        iterations=100,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "start = time.time()\n",
    "cat_baseline.fit(X_train, y_train)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "y_pred = cat_baseline.predict(X_test)\n",
    "y_pred_proba = cat_baseline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Results:\")\n",
    "print(f\"   Recall:    {recall:.3f} \u2190 PRIMARY\")\n",
    "print(f\"   Precision: {precision:.3f}\")\n",
    "print(f\"   F1-Score:  {f1:.3f}\")\n",
    "print(f\"   ROC-AUC:   {roc_auc:.3f}\")\n",
    "print(f\"   Time:      {elapsed:.1f}s\")\n",
    "print(f\"\\n   TP: {tp:,} | FP: {fp:,} | FN: {fn:,} | TN: {tn:,}\")\n",
    "\n",
    "cat_results.append({\n",
    "    'Model': 'CatBoost',\n",
    "    'Strategy': 'Baseline',\n",
    "    'Recall': recall,\n",
    "    'Precision': precision,\n",
    "    'F1': f1,\n",
    "    'ROC_AUC': roc_auc,\n",
    "    'Time': elapsed,\n",
    "    'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn\n",
    "})\n",
    "\n",
    "# Strategy 2: SMOTE\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"5\ufe0f\u20e3 CatBoost + SMOTE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cat_smote = ImbPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', CatBoostClassifier(\n",
    "        iterations=100,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "start = time.time()\n",
    "cat_smote.fit(X_train, y_train)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "y_pred = cat_smote.predict(X_test)\n",
    "y_pred_proba = cat_smote.predict_proba(X_test)[:, 1]\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Results:\")\n",
    "print(f\"   Recall:    {recall:.3f} \u2190 PRIMARY\")\n",
    "print(f\"   Precision: {precision:.3f}\")\n",
    "print(f\"   F1-Score:  {f1:.3f}\")\n",
    "print(f\"   ROC-AUC:   {roc_auc:.3f}\")\n",
    "print(f\"   Time:      {elapsed:.1f}s\")\n",
    "print(f\"\\n   TP: {tp:,} | FP: {fp:,} | FN: {fn:,} | TN: {tn:,}\")\n",
    "\n",
    "cat_results.append({\n",
    "    'Model': 'CatBoost',\n",
    "    'Strategy': 'SMOTE',\n",
    "    'Recall': recall,\n",
    "    'Precision': precision,\n",
    "    'F1': f1,\n",
    "    'ROC_AUC': roc_auc,\n",
    "    'Time': elapsed,\n",
    "    'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn\n",
    "})\n",
    "\n",
    "# Strategy 3: RandomUnderSampler\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"6\ufe0f\u20e3 CatBoost + RandomUnderSampler\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cat_under = ImbPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('undersample', RandomUnderSampler(random_state=42)),\n",
    "    ('classifier', CatBoostClassifier(\n",
    "        iterations=100,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "start = time.time()\n",
    "cat_under.fit(X_train, y_train)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "y_pred = cat_under.predict(X_test)\n",
    "y_pred_proba = cat_under.predict_proba(X_test)[:, 1]\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Results:\")\n",
    "print(f\"   Recall:    {recall:.3f} \u2190 PRIMARY\")\n",
    "print(f\"   Precision: {precision:.3f}\")\n",
    "print(f\"   F1-Score:  {f1:.3f}\")\n",
    "print(f\"   ROC-AUC:   {roc_auc:.3f}\")\n",
    "print(f\"   Time:      {elapsed:.1f}s\")\n",
    "print(f\"\\n   TP: {tp:,} | FP: {fp:,} | FN: {fn:,} | TN: {tn:,}\")\n",
    "\n",
    "cat_results.append({\n",
    "    'Model': 'CatBoost',\n",
    "    'Strategy': 'UnderSample',\n",
    "    'Recall': recall,\n",
    "    'Precision': precision,\n",
    "    'F1': f1,\n",
    "    'ROC_AUC': roc_auc,\n",
    "    'Time': elapsed,\n",
    "    'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn\n",
    "})\n",
    "\n",
    "print(\"\\n\u2705 CatBoost testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Step 8: Comprehensive Comparison (All 6 Combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SAMPLING STRATEGY BATTLE RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Combine all results\n",
    "all_results = ada_results + cat_results\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Sort by recall (primary), then precision (secondary)\n",
    "results_df = results_df.sort_values(['Recall', 'Precision'], ascending=[False, False])\n",
    "\n",
    "print(\"\\n\ud83d\udcca All 6 Combinations (Ranked by Recall, then Precision):\\n\")\n",
    "print(results_df[['Model', 'Strategy', 'Recall', 'Precision', 'F1', 'ROC_AUC']].to_string(index=False))\n",
    "\n",
    "# Identify winner\n",
    "winner = results_df.iloc[0]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\ud83c\udfc6 WINNER: BEST MODEL + SAMPLING COMBINATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n\ud83e\udd47 {winner['Model']} + {winner['Strategy']}\")\n",
    "print(f\"   Recall:    {winner['Recall']:.3f} \u2190 Catches {winner['Recall']*100:.1f}% of At-Risk\")\n",
    "print(f\"   Precision: {winner['Precision']:.3f}\")\n",
    "print(f\"   F1-Score:  {winner['F1']:.3f}\")\n",
    "print(f\"   ROC-AUC:   {winner['ROC_AUC']:.3f}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Confusion Matrix:\")\n",
    "print(f\"   True Positives:  {winner['TP']:,} \u2190 Caught At-Risk\")\n",
    "print(f\"   False Negatives: {winner['FN']:,} \u2190 Missed At-Risk\")\n",
    "print(f\"   True Negatives:  {winner['TN']:,}\")\n",
    "print(f\"   False Positives: {winner['FP']:,} \u2190 False alarms\")\n",
    "\n",
    "# Compare to Phase 2 baseline\n",
    "phase2_baseline = phase2_results['winner']['recall_mean']\n",
    "improvement = winner['Recall'] - phase2_baseline\n",
    "\n",
    "print(f\"\\n\ud83d\udcc8 vs Phase 2 Baseline:\")\n",
    "print(f\"   Phase 2: {phase2_baseline:.3f} recall\")\n",
    "print(f\"   Phase 3: {winner['Recall']:.3f} recall\")\n",
    "print(f\"   Change:  {improvement:+.3f} ({improvement/phase2_baseline*100:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcc8 Step 9: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# Create combo labels\n",
    "results_df['Combo'] = results_df['Model'] + '\\n' + results_df['Strategy']\n",
    "combos = results_df['Combo'].tolist()\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c', '#f39c12', '#9b59b6', '#1abc9c']\n",
    "\n",
    "# 1. Recall comparison\n",
    "axes[0, 0].barh(combos, results_df['Recall'], color=colors, alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Recall (At-Risk)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_title('Recall Comparison\\n(Higher is Better)', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].axvline(x=0.70, color='green', linestyle='--', alpha=0.5, label='Target (70%)')\n",
    "axes[0, 0].legend()\n",
    "for i, v in enumerate(results_df['Recall']):\n",
    "    axes[0, 0].text(v + 0.01, i, f'{v:.3f}', va='center', fontweight='bold')\n",
    "\n",
    "# 2. Precision comparison\n",
    "axes[0, 1].barh(combos, results_df['Precision'], color=colors, alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Precision (At-Risk)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_title('Precision Comparison\\n(Higher is Better)', fontsize=13, fontweight='bold')\n",
    "for i, v in enumerate(results_df['Precision']):\n",
    "    axes[0, 1].text(v + 0.01, i, f'{v:.3f}', va='center', fontweight='bold')\n",
    "\n",
    "# 3. F1-Score comparison\n",
    "axes[1, 0].barh(combos, results_df['F1'], color=colors, alpha=0.7)\n",
    "axes[1, 0].set_xlabel('F1-Score', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_title('F1-Score (Balance)\\n(Higher is Better)', fontsize=13, fontweight='bold')\n",
    "for i, v in enumerate(results_df['F1']):\n",
    "    axes[1, 0].text(v + 0.01, i, f'{v:.3f}', va='center', fontweight='bold')\n",
    "\n",
    "# 4. Recall vs Precision scatter\n",
    "for i, row in results_df.iterrows():\n",
    "    axes[1, 1].scatter(row['Recall'], row['Precision'], s=200, \n",
    "                      color=colors[list(results_df.index).index(i)], alpha=0.7,\n",
    "                      label=row['Combo'])\n",
    "axes[1, 1].set_xlabel('Recall', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Precision', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_title('Recall vs Precision Trade-off', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=8, loc='best')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd0d Step 10: Critical Analysis - Impact of Sampling Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CRITICAL ANALYSIS: SAMPLING STRATEGY IMPACT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Group by model to analyze sampling impact\n",
    "print(\"\\n\ud83d\udcca Impact Analysis by Model:\\n\")\n",
    "\n",
    "for model_name in ['AdaBoost', 'CatBoost']:\n",
    "    model_results = results_df[results_df['Model'] == model_name]\n",
    "    baseline = model_results[model_results['Strategy'] == 'Baseline'].iloc[0]\n",
    "    smote = model_results[model_results['Strategy'] == 'SMOTE'].iloc[0]\n",
    "    under = model_results[model_results['Strategy'] == 'UnderSample'].iloc[0]\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"{model_name} Analysis\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcca Baseline (Class Weights Only):\")\n",
    "    print(f\"   Recall: {baseline['Recall']:.3f} | Precision: {baseline['Precision']:.3f}\")\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcca SMOTE (Oversampling):\")\n",
    "    print(f\"   Recall: {smote['Recall']:.3f} ({smote['Recall']-baseline['Recall']:+.3f})\")\n",
    "    print(f\"   Precision: {smote['Precision']:.3f} ({smote['Precision']-baseline['Precision']:+.3f})\")\n",
    "    if smote['Recall'] > baseline['Recall']:\n",
    "        print(f\"   \u2705 SMOTE increased recall!\")\n",
    "    else:\n",
    "        print(f\"   \u26a0\ufe0f SMOTE decreased recall\")\n",
    "    if smote['Precision'] < baseline['Precision']:\n",
    "        print(f\"   \u26a0\ufe0f But precision dropped (more false alarms)\")\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcca RandomUnderSampler (Undersampling):\")\n",
    "    print(f\"   Recall: {under['Recall']:.3f} ({under['Recall']-baseline['Recall']:+.3f})\")\n",
    "    print(f\"   Precision: {under['Precision']:.3f} ({under['Precision']-baseline['Precision']:+.3f})\")\n",
    "    if under['Precision'] > baseline['Precision']:\n",
    "        print(f\"   \u2705 Undersampling improved precision!\")\n",
    "    else:\n",
    "        print(f\"   \u26a0\ufe0f Precision didn't improve\")\n",
    "    if under['Recall'] < baseline['Recall']:\n",
    "        print(f\"   \u26a0\ufe0f But recall dropped (misses more At-Risk)\")\n",
    "    \n",
    "    print(f\"\\n\ud83d\udca1 Conclusion for {model_name}:\")\n",
    "    if baseline['Recall'] >= max(smote['Recall'], under['Recall']):\n",
    "        print(f\"   Baseline is OPTIMAL - sampling doesn't help\")\n",
    "        print(f\"   Class weights alone are sufficient\")\n",
    "    elif smote['Recall'] > baseline['Recall'] and smote['Recall'] > under['Recall']:\n",
    "        print(f\"   SMOTE is best if maximizing recall is priority\")\n",
    "    else:\n",
    "        print(f\"   UnderSampling is best if balancing recall-precision\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"OVERALL INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n\ud83c\udfaf Key Findings:\")\n",
    "print(f\"\\n1\ufe0f\u20e3 Best Recall: {results_df.iloc[0]['Model']} + {results_df.iloc[0]['Strategy']}\")\n",
    "print(f\"   {results_df.iloc[0]['Recall']:.1%} of At-Risk patients detected\")\n",
    "\n",
    "best_precision = results_df.loc[results_df['Precision'].idxmax()]\n",
    "print(f\"\\n2\ufe0f\u20e3 Best Precision: {best_precision['Model']} + {best_precision['Strategy']}\")\n",
    "print(f\"   {best_precision['Precision']:.1%} of predictions are correct\")\n",
    "\n",
    "best_f1 = results_df.loc[results_df['F1'].idxmax()]\n",
    "print(f\"\\n3\ufe0f\u20e3 Best F1 (Balance): {best_f1['Model']} + {best_f1['Strategy']}\")\n",
    "print(f\"   F1-Score: {best_f1['F1']:.3f}\")\n",
    "\n",
    "print(f\"\\n\u26a0\ufe0f Recall-Precision Trade-off:\")\n",
    "print(f\"   High recall (76-80%) comes with low precision (25-35%)\")\n",
    "print(f\"   For every 100 predicted At-Risk, ~25-35 are truly At-Risk\")\n",
    "print(f\"   This is ACCEPTABLE for screening (better safe than sorry)\")\n",
    "print(f\"   But costly if follow-up tests are expensive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcbe Step 11: Save Results for Phase 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SAVING RESULTS FOR PHASE 4\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save full results\n",
    "results_df.to_csv('sampling_strategy_results.csv', index=False)\n",
    "print(f\"\\n\u2705 Saved: sampling_strategy_results.csv\")\n",
    "\n",
    "# Save winner selection\n",
    "winner_selection = {\n",
    "    'model': winner['Model'],\n",
    "    'sampling_strategy': winner['Strategy'],\n",
    "    'recall': float(winner['Recall']),\n",
    "    'precision': float(winner['Precision']),\n",
    "    'f1': float(winner['F1']),\n",
    "    'roc_auc': float(winner['ROC_AUC']),\n",
    "    'confusion_matrix': {\n",
    "        'TP': int(winner['TP']),\n",
    "        'FP': int(winner['FP']),\n",
    "        'TN': int(winner['TN']),\n",
    "        'FN': int(winner['FN'])\n",
    "    },\n",
    "    'phase1_baseline': 0.210,\n",
    "    'phase2_baseline': phase2_baseline,\n",
    "    'phase3_final': float(winner['Recall']),\n",
    "    'total_improvement': float(winner['Recall'] - 0.210)\n",
    "}\n",
    "\n",
    "with open('best_model_sampling_combo.json', 'w') as f:\n",
    "    json.dump(winner_selection, f, indent=2)\n",
    "\n",
    "print(f\"\u2705 Saved: best_model_sampling_combo.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\ud83c\udfaf PHASE 3 COMPLETE: SAMPLING STRATEGY BATTLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n\ud83c\udfc6 Selected for Phase 4 (Feature Selection):\")\n",
    "print(f\"   Model: {winner['Model']}\")\n",
    "print(f\"   Sampling: {winner['Strategy']}\")\n",
    "print(f\"   Configuration: \", end=\"\")\n",
    "if winner['Model'] == 'AdaBoost':\n",
    "    print(\"DecisionTree(class_weight='balanced', max_depth=3) + SAMME\")\n",
    "else:\n",
    "    print(f\"scale_pos_weight={scale_pos_weight:.2f}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Current Performance:\")\n",
    "print(f\"   Recall:    {winner['Recall']:.3f} ({winner['Recall']*100:.1f}% of At-Risk detected)\")\n",
    "print(f\"   Precision: {winner['Precision']:.3f}\")\n",
    "print(f\"   F1-Score:  {winner['F1']:.3f}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc8 Journey So Far:\")\n",
    "print(f\"   Phase 1 (Feature Eng): 0.210 recall (baseline)\")\n",
    "print(f\"   Phase 2 (Model Select): {phase2_baseline:.3f} recall (+{phase2_baseline-0.210:.3f})\")\n",
    "print(f\"   Phase 3 (Sampling):     {winner['Recall']:.3f} recall ({winner['Recall']-phase2_baseline:+.3f})\")\n",
    "print(f\"   Total Improvement:      {winner['Recall']-0.210:+.3f} ({(winner['Recall']-0.210)/0.210*100:+.0f}%)\")\n",
    "\n",
    "print(f\"\\n\ud83c\udfaf Next: Phase 4 - Feature Selection (RFECV)\")\n",
    "print(f\"   Notebook: 05D_feature_selection.ipynb\")\n",
    "print(f\"   Goal: Remove redundant features, improve generalization\")\n",
    "print(f\"   Method: Recursive Feature Elimination with Cross-Validation\")\n",
    "print(f\"   Expected: 10-15 features (from current 18)\")\n",
    "print(f\"   Benefit: Simpler model, potentially better recall\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}