{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìã Notebook 02: Data Preparation\n",
    "\n",
    "**Objective:** Prepare two versions of the dataset for modeling\n",
    "\n",
    "**What we'll do:**\n",
    "1. Load the clean data from Notebook 01\n",
    "2. Create Dataset B (Full) - all 21 features\n",
    "3. Create Dataset A (Clean) - remove potentially leaky features\n",
    "4. Prepare scaling strategy\n",
    "5. Save both datasets\n",
    "\n",
    "**Why two datasets?**\n",
    "- Dataset B (Full): Shows maximum predictive power (but might include target leakage)\n",
    "- Dataset A (Clean): More realistic for preventive screening (removes consequences of diabetes)\n",
    "- Comparing them demonstrates critical thinking about feature selection!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For scaling (we'll prepare the strategy, not fit yet)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 2: Load Data from Notebook 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('CDC_Diabetes_Dataset.csv')\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive data quality check\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA QUALITY VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Basic checks\n",
    "print(\"\\n1Ô∏è‚É£ BASIC CHECKS\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "# 2. Data types check\n",
    "print(\"\\n2Ô∏è‚É£ DATA TYPES\")\n",
    "print(\"-\" * 60)\n",
    "print(df.dtypes.value_counts())\n",
    "print(f\"\\n‚ö†Ô∏è All columns should be numeric (float64 or int64)\")\n",
    "\n",
    "# 3. Check for any non-numeric values\n",
    "print(\"\\n3Ô∏è‚É£ NON-NUMERIC VALUES CHECK\")\n",
    "print(\"-\" * 60)\n",
    "non_numeric_cols = df.select_dtypes(exclude=['number']).columns.tolist()\n",
    "if non_numeric_cols:\n",
    "    print(f\"‚ö†Ô∏è Non-numeric columns found: {non_numeric_cols}\")\n",
    "else:\n",
    "    print(\"‚úÖ All columns are numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Check value ranges for each feature\n",
    "print(\"\\n4Ô∏è‚É£ VALUE RANGE VERIFICATION\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Checking if values are within expected ranges...\\n\")\n",
    "\n",
    "# Expected ranges based on dataset description\n",
    "expected_ranges = {\n",
    "    'Diabetes_012': (0, 2),\n",
    "    'HighBP': (0, 1),\n",
    "    'HighChol': (0, 1),\n",
    "    'CholCheck': (0, 1),\n",
    "    'BMI': (12, 98),  # Reasonable human BMI range\n",
    "    'Smoker': (0, 1),\n",
    "    'Stroke': (0, 1),\n",
    "    'HeartDiseaseorAttack': (0, 1),\n",
    "    'PhysActivity': (0, 1),\n",
    "    'Fruits': (0, 1),\n",
    "    'Veggies': (0, 1),\n",
    "    'HvyAlcoholConsump': (0, 1),\n",
    "    'AnyHealthcare': (0, 1),\n",
    "    'NoDocbcCost': (0, 1),\n",
    "    'GenHlth': (1, 5),\n",
    "    'MentHlth': (0, 30),\n",
    "    'PhysHlth': (0, 30),\n",
    "    'DiffWalk': (0, 1),\n",
    "    'Sex': (0, 1),\n",
    "    'Age': (1, 13),\n",
    "    'Education': (1, 6),\n",
    "    'Income': (1, 8)\n",
    "}\n",
    "\n",
    "range_issues = []\n",
    "\n",
    "for col, (min_val, max_val) in expected_ranges.items():\n",
    "    actual_min = df[col].min()\n",
    "    actual_max = df[col].max()\n",
    "    \n",
    "    if actual_min < min_val or actual_max > max_val:\n",
    "        range_issues.append(col)\n",
    "        print(f\"‚ö†Ô∏è {col}: Expected [{min_val}-{max_val}], Got [{actual_min}-{actual_max}]\")\n",
    "\n",
    "if not range_issues:\n",
    "    print(\"‚úÖ All features are within expected ranges\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Found {len(range_issues)} features with unexpected ranges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Check for outliers in continuous features\n",
    "print(\"\\n5Ô∏è‚É£ OUTLIER DETECTION (Continuous Features)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "continuous_cols = ['BMI', 'MentHlth', 'PhysHlth']\n",
    "\n",
    "for col in continuous_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    outlier_pct = (len(outliers) / len(df)) * 100\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Range: [{df[col].min():.1f} - {df[col].max():.1f}]\")\n",
    "    print(f\"  Mean: {df[col].mean():.1f}, Median: {df[col].median():.1f}\")\n",
    "    print(f\"  IQR bounds: [{lower_bound:.1f} - {upper_bound:.1f}]\")\n",
    "    print(f\"  Outliers: {len(outliers):,} ({outlier_pct:.2f}%)\")\n",
    "    \n",
    "    if outlier_pct > 5:\n",
    "        print(f\"  ‚ö†Ô∏è High percentage of outliers (>5%)\")\n",
    "    else:\n",
    "        print(f\"  ‚úÖ Outlier percentage acceptable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Check for unexpected value distributions in binary features\n",
    "print(\"\\n6Ô∏è‚É£ BINARY FEATURE DISTRIBUTION CHECK\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "binary_cols = ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', \n",
    "               'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
    "               'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', \n",
    "               'DiffWalk', 'Sex']\n",
    "\n",
    "print(\"\\nChecking if binary features only contain 0 and 1...\\n\")\n",
    "\n",
    "binary_issues = []\n",
    "for col in binary_cols:\n",
    "    unique_vals = df[col].unique()\n",
    "    if not set(unique_vals).issubset({0.0, 1.0}):\n",
    "        binary_issues.append(col)\n",
    "        print(f\"‚ö†Ô∏è {col}: Contains values other than 0/1: {unique_vals}\")\n",
    "\n",
    "if not binary_issues:\n",
    "    print(\"‚úÖ All binary features contain only 0 and 1\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Found {len(binary_issues)} binary features with unexpected values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Target variable distribution check\n",
    "print(\"\\n7Ô∏è‚É£ TARGET VARIABLE CHECK\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "target_col = 'Diabetes_012'\n",
    "target_counts = df[target_col].value_counts().sort_index()\n",
    "\n",
    "print(\"\\nClass distribution:\")\n",
    "for cls, count in target_counts.items():\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"  Class {int(cls)}: {count:6,} ({pct:5.2f}%)\")\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "majority_class = target_counts.max()\n",
    "minority_class = target_counts.min()\n",
    "imbalance_ratio = majority_class / minority_class\n",
    "\n",
    "print(f\"\\nImbalance ratio: {imbalance_ratio:.1f}:1\")\n",
    "if imbalance_ratio > 10:\n",
    "    print(\"‚ö†Ô∏è SEVERE class imbalance detected (>10:1)\")\n",
    "    print(\"   ‚Üí We'll need to handle this in modeling phase\")\n",
    "elif imbalance_ratio > 3:\n",
    "    print(\"‚ö†Ô∏è Moderate class imbalance detected (>3:1)\")\n",
    "else:\n",
    "    print(\"‚úÖ Classes are relatively balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Final summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL DATA QUALITY SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "quality_checks = {\n",
    "    'No missing values': df.isnull().sum().sum() == 0,\n",
    "    'No duplicates': df.duplicated().sum() == 0,\n",
    "    'All numeric types': len(non_numeric_cols) == 0,\n",
    "    'Values in expected ranges': len(range_issues) == 0,\n",
    "    'Binary features valid': len(binary_issues) == 0,\n",
    "}\n",
    "\n",
    "print()\n",
    "for check, passed in quality_checks.items():\n",
    "    status = \"‚úÖ\" if passed else \"‚ö†Ô∏è\"\n",
    "    print(f\"{status} {check}\")\n",
    "\n",
    "all_passed = all(quality_checks.values())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if all_passed:\n",
    "    print(\"‚úÖ ALL DATA QUALITY CHECKS PASSED!\")\n",
    "    print(\"‚úÖ Dataset is ready for preprocessing and modeling\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è SOME ISSUES DETECTED - Review above for details\")\n",
    "    print(\"   (Note: Some issues like outliers may be expected)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Step 3: Remove Duplicates FIRST\n",
    "\n",
    "**Strategy:** Remove duplicates from the original dataset BEFORE creating Dataset A and Dataset B.\n",
    "\n",
    "**Why this order?**\n",
    "- Ensures both datasets have the same sample size\n",
    "- Makes model comparison fair (only difference is features, not samples)\n",
    "- Cleaner methodology\n",
    "\n",
    "**Important:** After this step, we work with deduplicated data for ALL subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STEP 3: REMOVE DUPLICATES FROM ORIGINAL DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Count duplicates in original data\n",
    "duplicates_original = df.duplicated().sum()\n",
    "duplicate_pct = (duplicates_original / len(df)) * 100\n",
    "\n",
    "print(f\"\\nüìä BEFORE deduplication:\")\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"Duplicate rows: {duplicates_original:,} ({duplicate_pct:.2f}%)\")\n",
    "print(f\"Unique rows: {len(df) - duplicates_original:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates and store in NEW variable\n",
    "df_deduplicated = df.drop_duplicates().copy()\n",
    "\n",
    "print(f\"\\n‚úÖ AFTER deduplication:\")\n",
    "print(f\"Before: {len(df):,} rows\")\n",
    "print(f\"After:  {len(df_deduplicated):,} rows\")\n",
    "print(f\"Removed: {len(df) - len(df_deduplicated):,} duplicate rows\")\n",
    "\n",
    "# Verify no duplicates remain\n",
    "remaining_duplicates = df_deduplicated.duplicated().sum()\n",
    "print(f\"\\n‚úÖ Verification: {remaining_duplicates} duplicates remaining (should be 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class balance is preserved\n",
    "print(f\"\\nüìä Class distribution AFTER deduplication:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for cls, count in df_deduplicated['Diabetes_012'].value_counts().sort_index().items():\n",
    "    pct = (count / len(df_deduplicated)) * 100\n",
    "    original_pct = (df['Diabetes_012'].value_counts().sort_index()[cls] / len(df)) * 100\n",
    "    print(f\"Class {int(cls)}: {count:6,} ({pct:5.2f}%) - Original: {original_pct:5.2f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ Class proportions preserved after deduplication!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM NOW ON, use df_deduplicated for ALL subsequent work\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ DEDUPLICATED DATASET READY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nWorking dataset: {len(df_deduplicated):,} rows, {len(df_deduplicated.columns)} columns\")\n",
    "print(f\"\\n‚ö†Ô∏è IMPORTANT: All subsequent steps will use df_deduplicated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 4: Identify Potentially Leaky Features\n",
    "\n",
    "**Target Leakage** occurs when a feature is a *consequence* of the target variable, rather than a *cause*.\n",
    "\n",
    "**Why this matters:**\n",
    "- If we include leaky features, our model might look great in testing...\n",
    "- But it won't work for **preventive screening** (before diabetes develops)\n",
    "- It would only work for **diagnostic confirmation** (after symptoms appear)\n",
    "\n",
    "**Potentially leaky features in this dataset:**\n",
    "\n",
    "| Feature | Description | Why It Might Be Leaky |\n",
    "|---------|-------------|----------------------|\n",
    "| `DiffWalk` | Difficulty walking or climbing stairs | Often a **consequence** of diabetes (neuropathy, poor circulation) |\n",
    "| `GenHlth` | Self-reported general health (1-5 scale) | People with diabetes naturally rate their health lower |\n",
    "| `PhysHlth` | Days of poor physical health (0-30) | Similar to GenHlth - likely consequence of diabetes |\n",
    "\n",
    "**Our strategy:**\n",
    "1. Create **Dataset B (Full)** - keep all features (shows maximum predictive power)\n",
    "2. Create **Dataset A (Clean)** - remove these 3 features (more realistic for prevention)\n",
    "3. Compare model performance on both\n",
    "4. Discuss implications in final report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features to remove for clean dataset\n",
    "potentially_leaky_features = ['DiffWalk', 'GenHlth', 'PhysHlth']\n",
    "\n",
    "print(\"Potentially leaky features identified:\")\n",
    "for feature in potentially_leaky_features:\n",
    "    print(f\"  - {feature}\")\n",
    "\n",
    "print(f\"\\nThese will be removed in Dataset A (Clean)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 4: Identify Potentially Leaky Features\n",
    "\n",
    "**Target Leakage** occurs when a feature is a *consequence* of the target variable, rather than a *cause*.\n",
    "\n",
    "**Why this matters:**\n",
    "- If we include leaky features, our model might look great in testing...\n",
    "- But it won't work for **preventive screening** (before diabetes develops)\n",
    "- It would only work for **diagnostic confirmation** (after symptoms appear)\n",
    "\n",
    "**Potentially leaky features in this dataset:**\n",
    "\n",
    "| Feature | Description | Why It Might Be Leaky |\n",
    "|---------|-------------|----------------------|\n",
    "| `DiffWalk` | Difficulty walking or climbing stairs | Often a **consequence** of diabetes (neuropathy, poor circulation) |\n",
    "| `GenHlth` | Self-reported general health (1-5 scale) | People with diabetes naturally rate their health lower |\n",
    "| `PhysHlth` | Days of poor physical health (0-30) | Similar to GenHlth - likely consequence of diabetes |\n",
    "\n",
    "**Our strategy:**\n",
    "1. Create **Dataset B (Full)** - keep all features (shows maximum predictive power)\n",
    "2. Create **Dataset A (Clean)** - remove these 3 features (more realistic for prevention)\n",
    "3. Compare model performance on both\n",
    "4. Discuss implications in final report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features to remove for clean dataset\n",
    "potentially_leaky_features = ['DiffWalk', 'GenHlth', 'PhysHlth']\n",
    "\n",
    "print(\"Potentially leaky features identified:\")\n",
    "for feature in potentially_leaky_features:\n",
    "    print(f\"  - {feature}\")\n",
    "\n",
    "print(f\"\\nThese will be removed in Dataset A (Clean)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 5: Create Dataset B (Full) - All Features\n",
    "\n",
    "**Dataset B includes all 21 features from the DEDUPLICATED data.**\n",
    "\n",
    "This represents the \"best case scenario\" where we have access to all available information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STEP 5: CREATING DATASET B (FULL) - ALL FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# CRITICAL: Use df_deduplicated (not df!)\n",
    "df_full = df_deduplicated.copy()\n",
    "\n",
    "print(f\"\\n‚úÖ Created Dataset B from deduplicated data\")\n",
    "print(f\"Source: df_deduplicated ({len(df_deduplicated):,} rows)\")\n",
    "print(f\"Result: df_full ({len(df_full):,} rows)\")\n",
    "\n",
    "# Verify\n",
    "assert len(df_full) == len(df_deduplicated), \"‚ùå ERROR: df_full has different size!\"\n",
    "print(f\"\\n‚úÖ Verification passed: Same size as deduplicated data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target for Dataset B\n",
    "X_full = df_full.drop('Diabetes_012', axis=1)\n",
    "y_full = df_full['Diabetes_012']\n",
    "\n",
    "print(\"=== Dataset B (Full) ===\")\n",
    "print(f\"Samples: {len(df_full):,}\")\n",
    "print(f\"Features shape: {X_full.shape}\")\n",
    "print(f\"Target shape: {y_full.shape}\")\n",
    "print(f\"\\nNumber of features: {X_full.shape[1]}\")\n",
    "print(f\"\\nFeature list:\")\n",
    "for i, col in enumerate(X_full.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Step 6: Create Dataset A (Clean) - Remove Leaky Features\n",
    "\n",
    "**Dataset A removes potentially leaky features from the DEDUPLICATED data.**\n",
    "\n",
    "This represents a more realistic scenario for preventive screening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STEP 6: CREATING DATASET A (CLEAN) - REMOVE LEAKY FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüö´ Removing features: {potentially_leaky_features}\")\n",
    "\n",
    "# CRITICAL: Use df_deduplicated (not df!)\n",
    "df_clean = df_deduplicated.drop(columns=potentially_leaky_features).copy()\n",
    "\n",
    "print(f\"\\n‚úÖ Created Dataset A from deduplicated data\")\n",
    "print(f\"Source: df_deduplicated ({len(df_deduplicated):,} rows)\")\n",
    "print(f\"Result: df_clean ({len(df_clean):,} rows)\")\n",
    "\n",
    "# Verify\n",
    "assert len(df_clean) == len(df_deduplicated), \"‚ùå ERROR: df_clean has different size!\"\n",
    "print(f\"\\n‚úÖ Verification passed: Same size as deduplicated data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target for Dataset A\n",
    "X_clean = df_clean.drop('Diabetes_012', axis=1)\n",
    "y_clean = df_clean['Diabetes_012']\n",
    "\n",
    "print(\"=== Dataset A (Clean) ===\")\n",
    "print(f\"Samples: {len(df_clean):,}\")\n",
    "print(f\"Features shape: {X_clean.shape}\")\n",
    "print(f\"Target shape: {y_clean.shape}\")\n",
    "print(f\"\\nNumber of features: {X_clean.shape[1]}\")\n",
    "print(f\"\\nRemoved features: {potentially_leaky_features}\")\n",
    "print(f\"\\nRemaining feature list:\")\n",
    "for i, col in enumerate(X_clean.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Step 7: Verify Both Datasets Are Identical in Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VERIFICATION: BOTH DATASETS SAME SIZE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Dataset Comparison:\")\n",
    "print(f\"Dataset B (Full):  {len(df_full):,} samples, {X_full.shape[1]} features\")\n",
    "print(f\"Dataset A (Clean): {len(df_clean):,} samples, {X_clean.shape[1]} features\")\n",
    "\n",
    "# Critical checks\n",
    "same_size = len(df_full) == len(df_clean)\n",
    "same_target = y_full.equals(y_clean)\n",
    "\n",
    "print(f\"\\n‚úÖ Same sample size? {same_size}\")\n",
    "if not same_size:\n",
    "    print(f\"   ‚ùå ERROR: Dataset sizes don't match!\")\n",
    "    print(f\"   Dataset B: {len(df_full):,}\")\n",
    "    print(f\"   Dataset A: {len(df_clean):,}\")\n",
    "    print(f\"   Difference: {abs(len(df_full) - len(df_clean)):,}\")\n",
    "    raise AssertionError(\"Dataset sizes must be identical!\")\n",
    "\n",
    "print(f\"‚úÖ Same target values? {same_target}\")\n",
    "if not same_target:\n",
    "    print(f\"   ‚ùå ERROR: Targets don't match!\")\n",
    "    raise AssertionError(\"Targets must be identical!\")\n",
    "\n",
    "print(f\"\\nüìä Target distribution (both datasets):\")\n",
    "print(\"-\" * 60)\n",
    "for cls, count in y_full.value_counts().sort_index().items():\n",
    "    pct = (count / len(y_full)) * 100\n",
    "    print(f\"Class {int(cls)}: {count:6,} ({pct:5.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ BOTH DATASETS READY FOR MODELING\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDataset B: {len(df_full):,} samples, {X_full.shape[1]} features (all features)\")\n",
    "print(f\"Dataset A: {len(df_clean):,} samples, {X_clean.shape[1]} features (removed 3 leaky features)\")\n",
    "print(f\"\\nüí° Same sample size ensures fair model comparison!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Step 8: Feature Scaling Strategy\n",
    "\n",
    "**Why do we need scaling?**\n",
    "\n",
    "Different features have different ranges:\n",
    "- `BMI`: ranges from 14 to 98\n",
    "- `Age`: ranges from 1 to 13\n",
    "- Binary features: only 0 or 1\n",
    "\n",
    "**Which algorithms need scaling?**\n",
    "- ‚úÖ **Need scaling:** Logistic Regression, SVM, KNN (distance-based)\n",
    "- ‚ùå **Don't need scaling:** Random Forest, Decision Trees, XGBoost (tree-based)\n",
    "\n",
    "**Our approach:**\n",
    "- We'll use `StandardScaler` (mean=0, std=1)\n",
    "- Apply it ONLY to continuous features: `BMI`, `MentHlth`, `PhysHlth` (if present)\n",
    "- Leave binary/ordinal features as-is\n",
    "\n",
    "**IMPORTANT:** We'll fit the scaler later (in training pipeline) to avoid data leakage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature types for scaling\n",
    "print(\"=== Feature Types for Scaling ===\")\n",
    "\n",
    "# Continuous features that need scaling\n",
    "continuous_features_full = ['BMI', 'MentHlth', 'PhysHlth']  # For Dataset B\n",
    "continuous_features_clean = ['BMI', 'MentHlth']             # For Dataset A (PhysHlth removed)\n",
    "\n",
    "print(f\"\\nDataset B (Full) - Continuous features to scale:\")\n",
    "for feat in continuous_features_full:\n",
    "    if feat in X_full.columns:\n",
    "        print(f\"  - {feat}: range [{X_full[feat].min():.0f} - {X_full[feat].max():.0f}]\")\n",
    "\n",
    "print(f\"\\nDataset A (Clean) - Continuous features to scale:\")\n",
    "for feat in continuous_features_clean:\n",
    "    if feat in X_clean.columns:\n",
    "        print(f\"  - {feat}: range [{X_clean[feat].min():.0f} - {X_clean[feat].max():.0f}]\")\n",
    "\n",
    "print(f\"\\n‚úÖ We'll apply StandardScaler to these features in the modeling pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Step 8: Feature Scaling Strategy\n",
    "\n",
    "**Why do we need scaling?**\n",
    "\n",
    "Different features have different ranges:\n",
    "- `BMI`: ranges from 14 to 98\n",
    "- `Age`: ranges from 1 to 13\n",
    "- Binary features: only 0 or 1\n",
    "\n",
    "**Which algorithms need scaling?**\n",
    "- ‚úÖ **Need scaling:** Logistic Regression, SVM, KNN (distance-based)\n",
    "- ‚ùå **Don't need scaling:** Random Forest, Decision Trees, XGBoost (tree-based)\n",
    "\n",
    "**Our approach:**\n",
    "- We'll use `StandardScaler` (mean=0, std=1)\n",
    "- Apply it ONLY to continuous features: `BMI`, `MentHlth`, `PhysHlth` (if present)\n",
    "- Leave binary/ordinal features as-is\n",
    "\n",
    "**IMPORTANT:** We'll fit the scaler later (in training pipeline) to avoid data leakage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature types for scaling\n",
    "print(\"=== Feature Types for Scaling ===\")\n",
    "\n",
    "# Continuous features that need scaling\n",
    "continuous_features_full = ['BMI', 'MentHlth', 'PhysHlth']  # For Dataset B\n",
    "continuous_features_clean = ['BMI', 'MentHlth']             # For Dataset A (PhysHlth removed)\n",
    "\n",
    "print(f\"\\nDataset B (Full) - Continuous features to scale:\")\n",
    "for feat in continuous_features_full:\n",
    "    if feat in X_full.columns:\n",
    "        print(f\"  - {feat}: range [{X_full[feat].min():.0f} - {X_full[feat].max():.0f}]\")\n",
    "\n",
    "print(f\"\\nDataset A (Clean) - Continuous features to scale:\")\n",
    "for feat in continuous_features_clean:\n",
    "    if feat in X_clean.columns:\n",
    "        print(f\"  - {feat}: range [{X_clean[feat].min():.0f} - {X_clean[feat].max():.0f}]\")\n",
    "\n",
    "print(f\"\\n‚úÖ We'll apply StandardScaler to these features in the modeling pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 9: Save Prepared Datasets\n",
    "\n",
    "We'll save both datasets for use in future notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataset B (Full)\n",
    "df_full.to_csv('dataset_B_full.csv', index=False)\n",
    "print(\"‚úÖ Saved: dataset_B_full.csv\")\n",
    "print(f\"   Shape: {df_full.shape}\")\n",
    "print(f\"   Features: {df_full.shape[1] - 1} (+ 1 target)\")\n",
    "\n",
    "# Save Dataset A (Clean)\n",
    "df_clean.to_csv('dataset_A_clean.csv', index=False)\n",
    "print(\"\\n‚úÖ Saved: dataset_A_clean.csv\")\n",
    "print(f\"   Shape: {df_clean.shape}\")\n",
    "print(f\"   Features: {df_clean.shape[1] - 1} (+ 1 target)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Data preparation complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 8: Summary Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_data = {\n",
    "    'Dataset': ['Dataset B (Full)', 'Dataset A (Clean)'],\n",
    "    'Total Samples': [len(df_full), len(df_clean)],\n",
    "    'Features': [X_full.shape[1], X_clean.shape[1]],\n",
    "    'Removed Features': ['-', ', '.join(potentially_leaky_features)],\n",
    "    'Use Case': ['Maximum predictive power', 'Realistic preventive screening']\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n=== Dataset Comparison ===\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç Critical Analysis: Data Preparation Decisions\n",
    "\n",
    "### **What We Did:**\n",
    "1. Created two versions of the dataset\n",
    "2. Identified potentially leaky features based on clinical reasoning\n",
    "3. Prepared scaling strategy for distance-based algorithms\n",
    "4. Kept data in raw form (no derived features yet)\n",
    "\n",
    "### **Why We Made These Choices:**\n",
    "\n",
    "#### **1. Two Datasets Approach**\n",
    "**Rationale:**\n",
    "- **Dataset B (Full)** allows us to see maximum achievable performance\n",
    "- **Dataset A (Clean)** ensures our model works for real-world prevention\n",
    "- Comparing them reveals the impact of potentially leaky features\n",
    "\n",
    "**Theory (from lectures):**\n",
    "- \"Data Understanding\" phase in CRISP-DM requires understanding causal relationships\n",
    "- Target leakage occurs when features are consequences rather than causes\n",
    "- Models with leakage may fail in production even with high test accuracy\n",
    "\n",
    "#### **2. Features Identified as Potentially Leaky**\n",
    "\n",
    "**`DiffWalk` (Difficulty Walking):**\n",
    "- **Clinical reasoning:** Diabetic neuropathy causes nerve damage ‚Üí difficulty walking\n",
    "- **Risk:** High - this is a known complication of uncontrolled diabetes\n",
    "- **Decision:** Remove in Dataset A\n",
    "\n",
    "**`GenHlth` (General Health Rating):**\n",
    "- **Clinical reasoning:** Self-reported health naturally decreases after diabetes diagnosis\n",
    "- **Risk:** Medium - could be both cause and consequence\n",
    "- **Decision:** Remove in Dataset A to be conservative\n",
    "\n",
    "**`PhysHlth` (Days of Poor Physical Health):**\n",
    "- **Clinical reasoning:** Similar to GenHlth - likely affected by diabetes symptoms\n",
    "- **Risk:** Medium - measures consequences of disease\n",
    "- **Decision:** Remove in Dataset A\n",
    "\n",
    "#### **3. Why NOT Remove Other Features?**\n",
    "\n",
    "**`Stroke` and `HeartDiseaseorAttack` - Why we kept them:**\n",
    "- While diabetes increases cardiovascular risk, these can occur independently\n",
    "- They represent comorbidities rather than direct consequences\n",
    "- Removing them might hurt model performance without clear benefit\n",
    "- If results show issues, we can revisit this decision\n",
    "\n",
    "#### **4. No Derived Features (Yet)**\n",
    "**Rationale:**\n",
    "- Start simple - raw features first\n",
    "- Tree-based models (Random Forest, XGBoost) can capture non-linearities automatically\n",
    "- Feature engineering adds complexity - only worth it if baseline results are poor\n",
    "- Easier to debug and interpret with original features\n",
    "\n",
    "**Potential future features (if needed):**\n",
    "- BMI categories (WHO standard: Underweight, Normal, Overweight, Obese)\n",
    "- Age groups (Young, Middle-age, Senior)\n",
    "- Interaction terms (e.g., Age √ó BMI)\n",
    "\n",
    "### **Strengths of Our Approach:**\n",
    "- ‚úÖ **Transparent:** Clear documentation of which features removed and why\n",
    "- ‚úÖ **Scientific:** Based on clinical knowledge and causal reasoning\n",
    "- ‚úÖ **Flexible:** Can easily test both datasets and compare results\n",
    "- ‚úÖ **Practical:** Dataset A addresses real-world preventive screening use case\n",
    "- ‚úÖ **Simple:** No premature feature engineering\n",
    "\n",
    "### **Limitations:**\n",
    "- ‚ö†Ô∏è **Uncertainty:** We can't be 100% certain which features are truly leaky without domain expert validation\n",
    "- ‚ö†Ô∏è **Trade-off:** Dataset A might have lower accuracy, but is more ethically sound for prevention\n",
    "- ‚ö†Ô∏è **Binary decision:** We're either keeping or removing features - no \"partial\" use\n",
    "- ‚ö†Ô∏è **Other potential leakage:** Features like `Stroke` or `HeartDiseaseorAttack` might also have some leakage\n",
    "\n",
    "### **Implications for Model Development:**\n",
    "\n",
    "**Expected outcomes:**\n",
    "1. **Dataset B** will likely show higher accuracy (especially if leakage exists)\n",
    "2. **Dataset A** will show more realistic performance for preventive screening\n",
    "3. Large performance difference suggests significant leakage in removed features\n",
    "4. Small performance difference validates our conservative feature removal\n",
    "\n",
    "**Next steps:**\n",
    "1. Exploratory analysis to understand feature relationships\n",
    "2. Clustering to identify risk segments\n",
    "3. Classification on BOTH datasets\n",
    "4. Compare results and discuss implications\n",
    "\n",
    "### **Ethical Considerations:**\n",
    "- Using leaky features in production could lead to **false confidence** in predictions\n",
    "- Healthcare systems need models that work for **early detection**, not just diagnosis confirmation\n",
    "- Transparent documentation allows future researchers to make informed decisions\n",
    "- Our two-dataset approach balances academic rigor with practical applicability\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "**What we accomplished:**\n",
    "- ‚úÖ Created Dataset B (Full) - 21 features, all information\n",
    "- ‚úÖ Created Dataset A (Clean) - 18 features, removed potential leakage\n",
    "- ‚úÖ Prepared scaling strategy for modeling pipeline\n",
    "- ‚úÖ Saved both datasets for future analysis\n",
    "\n",
    "**Ready for:**\n",
    "- üìä Notebook 03: Exploratory Analysis\n",
    "- üîµ Notebook 04: Clustering\n",
    "- üéØ Notebook 05: Classification\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
